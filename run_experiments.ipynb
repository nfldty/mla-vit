{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLA-ViT Comparative Evaluation on CIFAR-100\n",
    "\n",
    "This notebook evaluates and compares three Vision Transformer variants on the CIFAR-100 dataset:\n",
    "\n",
    "- **ViT-MHA**: A standard Vision Transformer using Multi-Head Attention.\n",
    "- **ViT-MLA**: A Vision Transformer using Multi-Head Latent Attention for reduced attention overhead.\n",
    "- **ViT-MLA+RoPE**: The MLA variant enhanced with Rotary Positional Embedding for improved positional encoding.\n",
    "\n",
    "All models are trained for 500 epochs with identical configurations to ensure fairness. Metrics such as accuracy and training time are recorded for comparison.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries for modeling, training, and visualization\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from models.vit_mha import ViT_MHA\n",
    "from models.vit_mla import ViT_MLA\n",
    "from models.vit_mla_rope import ViT_MLA_RoPE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set experiment-wide hyperparameters\n",
    "BATCH_SIZE = 128\n",
    "EPOCHS = 50\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CIFAR-100 with data augmentation and normalization\n",
    "transform = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5]*3, [0.5]*3),\n",
    "])\n",
    "train_set = torchvision.datasets.CIFAR100(root='dataset', train=True, download=True, transform=transform)\n",
    "test_set = torchvision.datasets.CIFAR100(root='dataset', train=False, download=True, transform=transform)\n",
    "train_loader = DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True, drop_last=True)\n",
    "test_loader = DataLoader(test_set, batch_size=BATCH_SIZE, shuffle=False, drop_last=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to train and evaluate a given model architecture\n",
    "def train_and_evaluate(model, model_name):\n",
    "    model = model.to(DEVICE)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=3e-4, betas=(0.9, 0.999))\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS, eta_min=1e-5)\n",
    "\n",
    "    best_acc = 0\n",
    "    train_accs, test_accs = [], []\n",
    "    start_time = time.time()\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        model.train()\n",
    "        correct, total = 0, 0\n",
    "        for imgs, labels in train_loader:\n",
    "            imgs, labels = imgs.to(DEVICE), labels.to(DEVICE)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(imgs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            _, preds = outputs.max(1)\n",
    "            correct += preds.eq(labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "        train_accs.append(100 * correct / total)\n",
    "\n",
    "        model.eval()\n",
    "        correct, total = 0, 0\n",
    "        with torch.no_grad():\n",
    "            for imgs, labels in test_loader:\n",
    "                imgs, labels = imgs.to(DEVICE), labels.to(DEVICE)\n",
    "                outputs = model(imgs)\n",
    "                _, preds = outputs.max(1)\n",
    "                correct += preds.eq(labels).sum().item()\n",
    "                total += labels.size(0)\n",
    "        acc = 100 * correct / total\n",
    "        test_accs.append(acc)\n",
    "        best_acc = max(best_acc, acc)\n",
    "        scheduler.step()\n",
    "\n",
    "        print(f\"[{model_name}] Epoch {epoch+1}: Train Acc: {train_accs[-1]:.2f}%, Test Acc: {acc:.2f}%\")\n",
    "\n",
    "    end_time = time.time()\n",
    "    print(f\"[{model_name}] Final Test Accuracy: {best_acc:.2f}% | Total Time: {end_time - start_time:.1f}s\")\n",
    "    return train_accs, test_accs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate and evaluate all model variants under identical settings\n",
    "model_classes = {\n",
    "    \"ViT-MHA\": ViT_MHA,\n",
    "    \"ViT-MLA\": ViT_MLA,\n",
    "    \"ViT-MLA+RoPE\": ViT_MLA_RoPE\n",
    "}\n",
    "\n",
    "results = {}\n",
    "\n",
    "for name, cls in model_classes.items():\n",
    "    print(f\"\\nRunning {name}...\")\n",
    "    model = cls()\n",
    "    results[name] = train_and_evaluate(model, name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize accuracy curves for each model\n",
    "plt.figure(figsize=(12, 6))\n",
    "for name, (train_accs, test_accs) in results.items():\n",
    "    plt.plot(test_accs, label=f'{name} Test Acc')\n",
    "\n",
    "plt.title(\"Test Accuracy over Epochs\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy (%)\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
